<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Nikki&#39;s Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Nikki&#39;s Blog Atom Feed"><title data-react-helmet="true">6-Neural Network Training | Nikki&#x27;s Blog</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://nikkon18.github.io//docs/Advanced Learning Algorithms/Training a Neural Network in TensorFlow"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="6-Neural Network Training | Nikki&#x27;s Blog"><meta data-react-helmet="true" name="description" content="TensorFlow implementation"><meta data-react-helmet="true" property="og:description" content="TensorFlow implementation"><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://nikkon18.github.io//docs/Advanced Learning Algorithms/Training a Neural Network in TensorFlow"><link data-react-helmet="true" rel="alternate" href="https://nikkon18.github.io//docs/Advanced Learning Algorithms/Training a Neural Network in TensorFlow" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://nikkon18.github.io//docs/Advanced Learning Algorithms/Training a Neural Network in TensorFlow" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.9c11c536.css">
<link rel="preload" href="/assets/js/runtime~main.852293d6.js" as="script">
<link rel="preload" href="/assets/js/main.026a2937.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Nikki&#x27;s Blog</b></a><a class="navbar__item navbar__link navbar__link--active" href="/docs/Supervised Machine Learning/Overview of Machine learning">Notes</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">ðŸŒœ</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">ðŸŒž</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_P2Lg"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><aside class="theme-doc-sidebar-container docSidebarContainer_rKC_"><div class="sidebar_CW9Y"><nav class="menu thin-scrollbar menu_SkdO"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/Supervised Machine Learning/Overview of Machine learning">Supervised Machine Learning</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active hasHref_VCh3" aria-current="page" href="/docs/Advanced Learning Algorithms/Neural networks intuition">Advanced Learning Algorithms</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Advanced Learning Algorithms/Neural networks intuition">1 - Neural networks intuition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Advanced Learning Algorithms/Neural network layer">2 - Neural network layer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Advanced Learning Algorithms/TensorFlow implementation">3 - TensorFlow implementation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Advanced Learning Algorithms/Neural network implementation in Python">4-Neural network implementation in Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Advanced Learning Algorithms/Speculations on AGI">5-Paths to Artificial General Intelligence (AGI)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Advanced Learning Algorithms/Training a Neural Network in TensorFlow">6-Neural Network Training</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Advanced Learning Algorithms/Activation Functions">7-Activation Functions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Advanced Learning Algorithms/Multiclass Classification">8-Multiclass Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Advanced Learning Algorithms/Advice for applying machine learning">9-Advice for applying machine learning</a></li></ul></li></ul></nav></div></aside><main class="docMainContainer_TCnq"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_DM6M"><div class="docItemContainer_vinB"><article><div class="tocCollapsible_jdIR theme-doc-toc-mobile tocMobile_TmEX"><button type="button" class="clean-btn tocCollapsibleButton_Fzxq">On this page</button></div><div class="theme-doc-markdown markdown"><h1>6-Neural Network Training</h1><h2 class="anchor anchorWithStickyNavbar_mojV" id="tensorflow-implementation">TensorFlow implementation<a class="hash-link" href="#tensorflow-implementation" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="neural-network-architecture">Neural Network Architecture<a class="hash-link" href="#neural-network-architecture" title="Direct link to heading">â€‹</a></h3><p>Our neural network architecture consists of an input layer, two hidden layers, and an output layer. The input layer takes in images represented by X, while the output layer predicts whether the image is a zero or a one. The first hidden layer has 25 units with a sigmoid activation function, followed by a second hidden layer with 15 units.</p><h3 class="anchor anchorWithStickyNavbar_mojV" id="training-process">Training Process<a class="hash-link" href="#training-process" title="Direct link to heading">â€‹</a></h3><p>we can use these code in TensorFlow to train this network:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">model = tf.keras.Sequential([</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tf.keras.layers.Dense(25, activation=&#x27;sigmoid&#x27;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tf.keras.layers.Dense(15, activation=&#x27;sigmoid&#x27;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tf.keras.layers.Dense(1, activation=&#x27;sigmoid&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">])</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model.compile(loss=&#x27;binary_crossentropy&#x27;, optimizer=&#x27;adam&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">model.fit(X, Y, epochs=10)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div><ol><li><p>Specify the Model</p><p>We start by defining the model using TensorFlow&#x27;s <code>Sequential</code> API. The <code>Sequential</code> model allows us to sequentially string together the layers of the neural network. In our case, we have three layers: the first hidden layer with 25 units and a sigmoid activation function, followed by the second hidden layer, and finally the output layer.</p></li><li><p>Compile the Model</p><p>Once the model is specified, we need to compile it using the <code>compile</code> function. The key step here is to specify the loss function we want to use. In our example, we use the binary cross-entropy loss function, which will be explained in more detail in the next video.</p></li><li><p>Train the Model</p><p>After compiling the model, we can now train it using the <code>fit</code> function. This function fits the model to the training dataset <code>X</code> and the corresponding ground truth labels <code>Y</code>. The parameter <code>epochs</code> determines the number of steps or iterations of the learning algorithm, such as gradient descent, to run.</p></li></ol><h3 class="anchor anchorWithStickyNavbar_mojV" id="key-points">Key Points<a class="hash-link" href="#key-points" title="Direct link to heading">â€‹</a></h3><p>It&#x27;s crucial to understand the code and the underlying concepts behind it. Simply calling the code without comprehension can lead to difficulties when things don&#x27;t work as expected. Having a conceptual mental framework of the training process helps with debugging and troubleshooting.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="training-details">Training Details<a class="hash-link" href="#training-details" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="introduction">Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">â€‹</a></h3><ul><li>Details of training a neural network in TensorFlow code</li><li>Comparison with logistic regression model training</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="logistic-regression-model-training">Logistic Regression Model Training<a class="hash-link" href="#logistic-regression-model-training" title="Direct link to heading">â€‹</a></h3><ol><li><p>Specify the input-output function of logistic regression:</p><ul><li>Logistic regression predicts f(x) = G(z), where G is the sigmoid function applied to the dot product of weights (W) and input features (X) plus the bias term (B).</li><li>The sigmoid function is defined as: G(z) = 1 / (1 + e^(-z)), where z = WÂ·X + B.</li></ul></li><li><p>Specify the loss and cost functions:</p><ul><li>Loss function for a single training example (x, y): negative y log(f(x)) - (1 - y) log(1 - f(x)).</li><li>Cost function (J) is the average of the loss function over the entire training set.</li></ul></li><li><p>Minimize the cost function using gradient descent:</p><ul><li>Update weights (W) and bias (B) using the gradients of J with respect to W and B.</li><li>Update equations: W = W - Î± <em> âˆ‚J/âˆ‚W, B = B - Î± </em> âˆ‚J/âˆ‚B.</li></ul></li></ol><h3 class="anchor anchorWithStickyNavbar_mojV" id="training-a-neural-network-in-tensorflow">Training a Neural Network in TensorFlow<a class="hash-link" href="#training-a-neural-network-in-tensorflow" title="Direct link to heading">â€‹</a></h3><ul><li>The same three steps are used to train a neural network.</li></ul><h4 class="anchor anchorWithStickyNavbar_mojV" id="step-1-compute-output">Step 1: Compute Output<a class="hash-link" href="#step-1-compute-output" title="Direct link to heading">â€‹</a></h4><ul><li><p>Specify the neural network architecture using TensorFlow code.</p></li><li><p>Example code:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">model = tf.keras.Sequential([</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tf.keras.layers.Dense(25, activation=&#x27;sigmoid&#x27;, input_shape=(input_size,)),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tf.keras.layers.Dense(15, activation=&#x27;sigmoid&#x27;),</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    tf.keras.layers.Dense(1, activation=&#x27;sigmoid&#x27;)</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">])</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div></li><li><p>The code specifies the number of hidden units in each layer and the activation function used.</p></li></ul><h4 class="anchor anchorWithStickyNavbar_mojV" id="step-2-specify-loss-function">Step 2: Specify Loss Function<a class="hash-link" href="#step-2-specify-loss-function" title="Direct link to heading">â€‹</a></h4><ul><li><p>Use the binary cross-entropy loss function for classification problems:</p><ul><li>Loss function: -y log(f(x)) - (1 - y) log(1 - f(x)), where y is the ground truth label and f(x) is the output of the neural network.</li></ul></li><li><p>Example code:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=&#x27;sgd&#x27;)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div></li></ul><h4 class="anchor anchorWithStickyNavbar_mojV" id="step-3-minimize-cost-function">Step 3: Minimize Cost Function<a class="hash-link" href="#step-3-minimize-cost-function" title="Direct link to heading">â€‹</a></h4><ul><li><p>Use an optimization algorithm (e.g., gradient descent) to minimize the cost function.</p></li><li><p>TensorFlow&#x27;s <code>fit</code> function handles the optimization process.</p></li><li><p>Example code:</p><div class="codeBlockContainer_I0IT theme-code-block"><div class="codeBlockContent_wNvx"><pre tabindex="0" class="prism-code language-text codeBlock_jd64 thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_mRuA"><span class="token-line" style="color:#393A34"><span class="token plain">model.fit(X, y, epochs=100)</span><br></span></code></pre><button type="button" aria-label="Copy code to clipboard" class="copyButton_wuS7 clean-btn">Copy</button></div></div></li><li><p>TensorFlow uses backpropagation to compute the partial derivatives required for optimization.</p></li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">â€‹</a></h3><ul><li>TensorFlow simplifies the training process by providing high-level functions and libraries.</li><li>Libraries like TensorFlow and PyTorch are commonly used for neural network implementations.</li><li>Understanding the underlying principles helps in troubleshooting and customization.</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Advanced Learning Algorithms/13-Training a Neural Network in TensorFlow.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_foO9"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/Advanced Learning Algorithms/Speculations on AGI"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">5-Paths to Artificial General Intelligence (AGI)</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/Advanced Learning Algorithms/Activation Functions"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">7-Activation Functions</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_cNA8 thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#tensorflow-implementation" class="table-of-contents__link toc-highlight">TensorFlow implementation</a><ul><li><a href="#neural-network-architecture" class="table-of-contents__link toc-highlight">Neural Network Architecture</a></li><li><a href="#training-process" class="table-of-contents__link toc-highlight">Training Process</a></li><li><a href="#key-points" class="table-of-contents__link toc-highlight">Key Points</a></li></ul></li><li><a href="#training-details" class="table-of-contents__link toc-highlight">Training Details</a><ul><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#logistic-regression-model-training" class="table-of-contents__link toc-highlight">Logistic Regression Model Training</a></li><li><a href="#training-a-neural-network-in-tensorflow" class="table-of-contents__link toc-highlight">Training a Neural Network in TensorFlow</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs">Notes</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2023</div></div></div></footer></div>
<script src="/assets/js/runtime~main.852293d6.js"></script>
<script src="/assets/js/main.026a2937.js"></script>
</body>
</html>