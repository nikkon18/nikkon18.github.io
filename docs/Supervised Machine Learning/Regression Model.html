<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Nikki&#39;s Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Nikki&#39;s Blog Atom Feed"><title data-react-helmet="true">2 - Regression Model | Nikki&#x27;s Blog</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://nikkon18.github.io//docs/Supervised Machine Learning/Regression Model"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="2 - Regression Model | Nikki&#x27;s Blog"><meta data-react-helmet="true" name="description" content="Linear Regression lesson1"><meta data-react-helmet="true" property="og:description" content="Linear Regression lesson1"><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://nikkon18.github.io//docs/Supervised Machine Learning/Regression Model"><link data-react-helmet="true" rel="alternate" href="https://nikkon18.github.io//docs/Supervised Machine Learning/Regression Model" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://nikkon18.github.io//docs/Supervised Machine Learning/Regression Model" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.9c11c536.css">
<link rel="preload" href="/assets/js/runtime~main.852293d6.js" as="script">
<link rel="preload" href="/assets/js/main.026a2937.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">Nikki&#x27;s Blog</b></a><a class="navbar__item navbar__link navbar__link--active" href="/docs/Supervised Machine Learning/Overview of Machine learning">Notes</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">ðŸŒœ</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">ðŸŒž</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_P2Lg"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><aside class="theme-doc-sidebar-container docSidebarContainer_rKC_"><div class="sidebar_CW9Y"><nav class="menu thin-scrollbar menu_SkdO"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active hasHref_VCh3" aria-current="page" href="/docs/Supervised Machine Learning/Overview of Machine learning">Supervised Machine Learning</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Supervised Machine Learning/Overview of Machine learning">1 - Overview of Machine learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Supervised Machine Learning/Regression Model">2 - Regression Model</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Supervised Machine Learning/Train the model with gradient descent">3 - Train the model with gradient descent</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Supervised Machine Learning/Mutiple linear regression">4 - Mutiple linear regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Supervised Machine Learning/Gradient descent in practice">5 - Gradient descent in practice</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Supervised Machine Learning/classification with logistic regression">6 - classification with logistic regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Supervised Machine Learning/The problem of overditting">7 - The problem of overditting</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/Advanced Learning Algorithms/Neural networks intuition">Advanced Learning Algorithms</a></div></li></ul></nav></div></aside><main class="docMainContainer_TCnq"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_DM6M"><div class="docItemContainer_vinB"><article><div class="tocCollapsible_jdIR theme-doc-toc-mobile tocMobile_TmEX"><button type="button" class="clean-btn tocCollapsibleButton_Fzxq">On this page</button></div><div class="theme-doc-markdown markdown"><h1>2 - Regression Model</h1><h2 class="anchor anchorWithStickyNavbar_mojV" id="linear-regression-lesson1">Linear Regression lesson1<a class="hash-link" href="#linear-regression-lesson1" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="introduction">Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">â€‹</a></h3><ul><li>Supervised learning is a process of training a model using a dataset with labeled outputs.</li><li>Linear regression is a type of supervised learning model that predicts numerical outputs, such as the price of a house based on its size.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="linear-regression-model">Linear Regression Model<a class="hash-link" href="#linear-regression-model" title="Direct link to heading">â€‹</a></h3><ul><li>Linear regression model fits a straight line to the data.</li><li>The model can be used to predict the price of a house based on its size.</li><li>Linear regression is a type of regression model.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="regression-vs-classification">Regression vs. Classification<a class="hash-link" href="#regression-vs-classification" title="Direct link to heading">â€‹</a></h3><ul><li>Regression models predict numerical outputs, while classification models predict discrete categories.</li><li>Linear regression is an example of a regression model.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="training-set">Training Set<a class="hash-link" href="#training-set" title="Direct link to heading">â€‹</a></h3><ul><li>The dataset used to train the model is called a training set.</li><li>The input variable in machine learning notation is denoted as lowercase x.</li><li>The output variable is denoted as lowercase y.</li><li>The training set contains multiple training examples, with each row corresponding to a different example.</li><li>The total number of examples is denoted as m.</li><li>A specific example is denoted as (x^i, y^i), where i is an index into the training set.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="notation-for-describing-data">Notation for Describing Data<a class="hash-link" href="#notation-for-describing-data" title="Direct link to heading">â€‹</a></h3><ul><li>Standard notation to denote the input is lowercase x.</li><li>The output variable is denoted as lowercase y.</li><li>To refer to a specific training example, use the notation x^(i), y^(i).</li><li>The superscript i refers to a specific row in the dataset.</li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="linear-regression-lesson2">Linear Regression lesson2<a class="hash-link" href="#linear-regression-lesson2" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="introduction-1">Introduction<a class="hash-link" href="#introduction-1" title="Direct link to heading">â€‹</a></h3><ul><li>Supervised learning algorithm inputs a dataset.</li><li>Training set in supervised learning includes input features and output targets.</li><li>The job of the function f is to take a new input x and output an estimate or prediction y-hat.</li><li>The prediction y-hat is the estimated value of y.</li><li>The model&#x27;s prediction is the estimated value of y.</li><li>The function f is called the model, x is the input or input feature, and y-hat is the output or prediction.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="linear-regression">Linear Regression<a class="hash-link" href="#linear-regression" title="Direct link to heading">â€‹</a></h3><ul><li>Linear regression is the process of fitting a straight line to a set of data points.</li><li>The function f is a straight line represented as <code>f(x) = wx + b</code>.</li><li><code>w</code> and <code>b</code> are numbers chosen to determine the prediction <code>y-hat</code> based on the input feature <code>x</code>.</li><li>Linear regression is a simple and easy-to-work-with foundation for more complex models.</li><li>Linear regression with one variable is called univariate linear regression.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="cost-function">Cost Function<a class="hash-link" href="#cost-function" title="Direct link to heading">â€‹</a></h3><ul><li>Constructing a cost function is one of the most important things in making linear regression work.</li><li>The cost function measures the difference between the predicted value and the actual value of the output target.</li><li>The goal is to minimize the cost function to get the best-fit line for the data.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">â€‹</a></h3><ul><li>Supervised learning algorithms input a dataset and output a function f that makes predictions based on the input features.</li><li>Linear regression is a simple and easy-to-work-with foundation for more complex models.</li><li>Constructing a cost function is important to minimize the difference between predicted and actual output values.</li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="cost-function-formula">Cost function formula<a class="hash-link" href="#cost-function-formula" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="introduction-2">Introduction<a class="hash-link" href="#introduction-2" title="Direct link to heading">â€‹</a></h3><ul><li>Linear regression is the process of fitting a straight line to a set of data points.</li><li>The function f is a straight line represented as <code>f(x) = wx + b</code>.</li><li><code>w</code> and <code>b</code> are called the parameters or coefficients of the model.</li><li>The goal of linear regression is to choose values for <code>w</code> and <code>b</code> so that the line defined by <code>f</code> fits the data well.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="cost-function-1">Cost Function<a class="hash-link" href="#cost-function-1" title="Direct link to heading">â€‹</a></h3><ul><li>The cost function measures how well a line fits the training data.</li><li>The squared error cost function is widely used in machine learning for linear regression.</li><li>The cost function is defined as <code>J(w, b) = 1/(2m) * sum((f(x^i) - y^i)^2)</code> where <code>m</code> is the number of training examples.</li><li>The cost function compares the predicted value <code>f(x^i)</code> to the true target value <code>y^i</code>.</li><li>The cost function is used to find values of <code>w</code> and <code>b</code> that make the cost function small.</li><li>By convention, the cost function is divided by <code>2m</code> to make calculations look neater.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="conclusion-1">Conclusion<a class="hash-link" href="#conclusion-1" title="Direct link to heading">â€‹</a></h3><ul><li>Linear regression involves fitting a straight line to a set of data points.</li><li>The cost function measures how well a line fits the training data.</li><li>The squared error cost function is widely used in machine learning for linear regression.</li><li>The cost function is used to find values of <code>w</code> and <code>b</code> that make the cost function small.</li></ul><h2 class="anchor anchorWithStickyNavbar_mojV" id="cost-function-intuition">Cost Function Intuition<a class="hash-link" href="#cost-function-intuition" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="the-cost-function-j-measures-how-well-a-choice-of-w-and-b-fit-the-training-data">The cost function J measures how well a choice of w and b fit the training data.<a class="hash-link" href="#the-cost-function-j-measures-how-well-a-choice-of-w-and-b-fit-the-training-data" title="Direct link to heading">â€‹</a></h3><ul><li>The goal is to find values for w and b that minimize J, making the squared errors as small as possible.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="jw-b--12m--Ïƒi1-to-m-fwxi---yi2">J(w, b) = 1/2m <!-- -->*<!-- --> Î£(i=1 to m) (fw(x(i)) - y(i))^2<a class="hash-link" href="#jw-b--12m--Ïƒi1-to-m-fwxi---yi2" title="Direct link to heading">â€‹</a></h3><ul><li>Foreach training example (x(i), y(i)), the cost function calculates the squared difference between the predicted value fw(x(i)) and the actual value y(i).</li><li>The cost function then takes the average of these squared differences across all training examples.</li><li>The factor of 1/2m is included to make calculations simpler.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="minimizing-the-cost-function">Minimizing the Cost Function<a class="hash-link" href="#minimizing-the-cost-function" title="Direct link to heading">â€‹</a></h3><ul><li>The goal is to find values for w and b that minimize the cost function J.</li><li>This is done using optimization algorithms such as gradient descent.</li><li>Gradient descent iteratively adjusts the values of w and b to find the minimum of the cost function.</li><li>By updating the values of w and b in the direction of steepest descent, the algorithm converges to the minimum.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="visualizing-the-cost-function">Visualizing the Cost Function<a class="hash-link" href="#visualizing-the-cost-function" title="Direct link to heading">â€‹</a></h3><ul><li>The cost function J(w, b) can be visualized as a bowl-shaped surface in three-dimensional space.</li><li>The x-axis represents the value of w, the y-axis represents the value of b, and the z-axis represents the value of J.</li><li>The goal is to find the values of w and b that correspond to the lowest point on the surface, indicating the minimum cost.</li></ul><h3 class="anchor anchorWithStickyNavbar_mojV" id="conclusion-2">Conclusion<a class="hash-link" href="#conclusion-2" title="Direct link to heading">â€‹</a></h3><ul><li>The cost function measures how well a choice of w and b fit the training data.</li><li>The goal is to find values for w and b that minimize the cost function.</li><li>Optimization algorithms such as gradient descent are used to iteratively update the values of w and b to converge to the minimum of the cost function.</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Supervised Machine Learning/2-Regression Model.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_foO9"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/Supervised Machine Learning/Overview of Machine learning"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">1 - Overview of Machine learning</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/Supervised Machine Learning/Train the model with gradient descent"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">3 - Train the model with gradient descent</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_cNA8 thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#linear-regression-lesson1" class="table-of-contents__link toc-highlight">Linear Regression lesson1</a><ul><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#linear-regression-model" class="table-of-contents__link toc-highlight">Linear Regression Model</a></li><li><a href="#regression-vs-classification" class="table-of-contents__link toc-highlight">Regression vs. Classification</a></li><li><a href="#training-set" class="table-of-contents__link toc-highlight">Training Set</a></li><li><a href="#notation-for-describing-data" class="table-of-contents__link toc-highlight">Notation for Describing Data</a></li></ul></li><li><a href="#linear-regression-lesson2" class="table-of-contents__link toc-highlight">Linear Regression lesson2</a><ul><li><a href="#introduction-1" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#linear-regression" class="table-of-contents__link toc-highlight">Linear Regression</a></li><li><a href="#cost-function" class="table-of-contents__link toc-highlight">Cost Function</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></li><li><a href="#cost-function-formula" class="table-of-contents__link toc-highlight">Cost function formula</a><ul><li><a href="#introduction-2" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#cost-function-1" class="table-of-contents__link toc-highlight">Cost Function</a></li><li><a href="#conclusion-1" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></li><li><a href="#cost-function-intuition" class="table-of-contents__link toc-highlight">Cost Function Intuition</a><ul><li><a href="#the-cost-function-j-measures-how-well-a-choice-of-w-and-b-fit-the-training-data" class="table-of-contents__link toc-highlight">The cost function J measures how well a choice of w and b fit the training data.</a></li><li><a href="#jw-b--12m--Ïƒi1-to-m-fwxi---yi2" class="table-of-contents__link toc-highlight">J(w, b) = 1/2m * Î£(i=1 to m) (fw(x(i)) - y(i))^2</a></li><li><a href="#minimizing-the-cost-function" class="table-of-contents__link toc-highlight">Minimizing the Cost Function</a></li><li><a href="#visualizing-the-cost-function" class="table-of-contents__link toc-highlight">Visualizing the Cost Function</a></li><li><a href="#conclusion-2" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs">Notes</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2023</div></div></div></footer></div>
<script src="/assets/js/runtime~main.852293d6.js"></script>
<script src="/assets/js/main.026a2937.js"></script>
</body>
</html>