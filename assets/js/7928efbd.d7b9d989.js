"use strict";(self.webpackChunkmyblog=self.webpackChunkmyblog||[]).push([[8959],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>h});var i=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},r=Object.keys(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=i.createContext({}),d=function(e){var t=i.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},u=function(e){var t=d(e.components);return i.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},m=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,s=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),m=d(n),h=a,p=m["".concat(s,".").concat(h)]||m[h]||c[h]||r;return n?i.createElement(p,l(l({ref:t},u),{},{components:n})):i.createElement(p,l({ref:t},u))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,l=new Array(r);l[0]=m;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:a,l[1]=o;for(var d=2;d<r;d++)l[d]=n[d];return i.createElement.apply(null,l)}return i.createElement.apply(null,n)}m.displayName="MDXCreateElement"},8606:(e,t,n)=>{n.r(t),n.d(t,{frontMatter:()=>r,contentTitle:()=>l,metadata:()=>o,toc:()=>s,default:()=>u});var i=n(7462),a=(n(7294),n(3905));const r={},l="3 - Train the model with gradient descent",o={unversionedId:"Supervised Machine Learning/Train the model with gradient descent",id:"Supervised Machine Learning/Train the model with gradient descent",title:"3 - Train the model with gradient descent",description:"Gradient Descent for Minimizing Cost Function",source:"@site/docs/Supervised Machine Learning/3-Train the model with gradient descent.md",sourceDirName:"Supervised Machine Learning",slug:"/Supervised Machine Learning/Train the model with gradient descent",permalink:"/docs/Supervised Machine Learning/Train the model with gradient descent",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Supervised Machine Learning/3-Train the model with gradient descent.md",tags:[],version:"current",sidebarPosition:3,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"2 - Regression Model",permalink:"/docs/Supervised Machine Learning/Regression Model"},next:{title:"4 - Mutiple linear regression",permalink:"/docs/Supervised Machine Learning/Mutiple linear regression"}},s=[{value:"Gradient Descent for Minimizing Cost Function",id:"gradient-descent-for-minimizing-cost-function",children:[{value:"Introduction",id:"introduction",children:[],level:3},{value:"Objective",id:"objective",children:[],level:3},{value:"Algorithm",id:"algorithm",children:[],level:3},{value:"Visualizing Gradient Descent",id:"visualizing-gradient-descent",children:[],level:3},{value:"Properties of Gradient Descent",id:"properties-of-gradient-descent",children:[],level:3},{value:"Conclusion",id:"conclusion",children:[],level:3}],level:2},{value:"Implementing Gradient Descent Algorithm",id:"implementing-gradient-descent-algorithm",children:[{value:"Introduction",id:"introduction-1",children:[],level:3},{value:"Understanding the Equation",id:"understanding-the-equation",children:[],level:3},{value:"Updating <code>w</code> and <code>b</code>",id:"updating-w-and-b",children:[],level:3},{value:"Simultaneous Update",id:"simultaneous-update",children:[],level:3},{value:"Incorrect Implementation",id:"incorrect-implementation",children:[],level:3},{value:"Conclusion",id:"conclusion-1",children:[],level:3}],level:2},{value:"Gradient Descent Intuition and Learning Rate",id:"gradient-descent-intuition-and-learning-rate",children:[{value:"Introduction",id:"introduction-2",children:[],level:3},{value:"Gradient Descent on One Parameter",id:"gradient-descent-on-one-parameter",children:[],level:3},{value:"Choosing the Learning Rate Alpha",id:"choosing-the-learning-rate-alpha",children:[],level:3},{value:"Visualizing Learning Rate",id:"visualizing-learning-rate",children:[],level:3},{value:"Learning Rate Tuning",id:"learning-rate-tuning",children:[],level:3},{value:"Conclusion",id:"conclusion-2",children:[],level:3}],level:2}],d={toc:s};function u(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,i.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"3---train-the-model-with-gradient-descent"},"3 - Train the model with gradient descent"),(0,a.kt)("h2",{id:"gradient-descent-for-minimizing-cost-function"},"Gradient Descent for Minimizing Cost Function"),(0,a.kt)("h3",{id:"introduction"},"Introduction"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Gradient descent is an algorithm used to minimize any function, not just a cost function for linear regression."),(0,a.kt)("li",{parentName:"ul"},"It can be used to minimize a cost function, J(w,b), which is a measure of how well the line f(x) fits the data points.")),(0,a.kt)("h3",{id:"objective"},"Objective"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"The objective is to minimize J over the parameters w and b."),(0,a.kt)("li",{parentName:"ul"},"You want to pick values for w and b that give you the smallest possible value of J.")),(0,a.kt)("h3",{id:"algorithm"},"Algorithm"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Start with some initial guesses for w and b. A common choice is to set them both to 0."),(0,a.kt)("li",{parentName:"ul"},"Keep changing the parameters w and b a bit every time to try to reduce the cost J of w, b until hopefully J settles at or near a minimum."),(0,a.kt)("li",{parentName:"ul"},"Gradient descent applies to more general functions, including other cost functions that work with models that have more than two parameters.")),(0,a.kt)("h3",{id:"visualizing-gradient-descent"},"Visualizing Gradient Descent"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Imagine that the cost function J is a view of a slightly hilly outdoor park or a golf course where the high points are hills and the low points are valleys."),(0,a.kt)("li",{parentName:"ul"},"The goal is to start at the top of a hill and get to the bottom of one of these valleys as efficiently as possible."),(0,a.kt)("li",{parentName:"ul"},"The algorithm spins around 360 degrees and looks around to find the direction of steepest descent."),(0,a.kt)("li",{parentName:"ul"},"The direction of steepest descent is the best direction to take your next step downhill."),(0,a.kt)("li",{parentName:"ul"},"After taking this step, repeat the process and keep going until you find yourself at the bottom of the valley, at a local minimum.")),(0,a.kt)("h3",{id:"properties-of-gradient-descent"},"Properties of Gradient Descent"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Gradient descent has an interesting property where the choice of initial parameters affects the final result."),(0,a.kt)("li",{parentName:"ul"},"If you start the algorithm with different initial parameters, you may end up at a different local minimum."),(0,a.kt)("li",{parentName:"ul"},"The bottoms of both the first and the second valleys are called local minima.")),(0,a.kt)("h3",{id:"conclusion"},"Conclusion"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Gradient descent is an algorithm used to minimize a cost function J over the parameters w and b."),(0,a.kt)("li",{parentName:"ul"},"The algorithm starts with some initial guesses for w and b and keeps changing the parameters to reduce the cost J until it settles at or near a minimum."),(0,a.kt)("li",{parentName:"ul"},"The algorithm finds the direction of steepest descent and takes steps downhill until it reaches a local minimum."),(0,a.kt)("li",{parentName:"ul"},"The choice of initial parameters affects the final result, and different initial parameters may lead to different local minima.")),(0,a.kt)("h2",{id:"implementing-gradient-descent-algorithm"},"Implementing Gradient Descent Algorithm"),(0,a.kt)("h3",{id:"introduction-1"},"Introduction"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Implementing the gradient descent algorithm"),(0,a.kt)("li",{parentName:"ul"},"Updating the parameter ",(0,a.kt)("inlineCode",{parentName:"li"},"w")," on each step"),(0,a.kt)("li",{parentName:"ul"},"The update equation: ",(0,a.kt)("inlineCode",{parentName:"li"},"w = w - \u03b1 * (dJ(wb)/dw)"))),(0,a.kt)("h3",{id:"understanding-the-equation"},"Understanding the Equation"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"=")," is the assignment operator in programming contexts"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"\u03b1")," is the learning rate, a small positive number between 0 and 1"),(0,a.kt)("li",{parentName:"ul"},"Learning rate controls the step size downhill"),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"(dJ(wb)/dw)")," is the derivative term of the cost function ",(0,a.kt)("inlineCode",{parentName:"li"},"J")),(0,a.kt)("li",{parentName:"ul"},'Derivative term indicates the direction to take a "baby step"')),(0,a.kt)("h3",{id:"updating-w-and-b"},"Updating ",(0,a.kt)("inlineCode",{parentName:"h3"},"w")," and ",(0,a.kt)("inlineCode",{parentName:"h3"},"b")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Model has two parameters, ",(0,a.kt)("inlineCode",{parentName:"li"},"w")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"b")),(0,a.kt)("li",{parentName:"ul"},"To update ",(0,a.kt)("inlineCode",{parentName:"li"},"b"),", use similar equation with ",(0,a.kt)("inlineCode",{parentName:"li"},"dJ(wb)/db")),(0,a.kt)("li",{parentName:"ul"},"Repeat the update steps until the algorithm converges"),(0,a.kt)("li",{parentName:"ul"},"Convergence is when ",(0,a.kt)("inlineCode",{parentName:"li"},"w")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"b")," no longer change much with each step")),(0,a.kt)("h3",{id:"simultaneous-update"},"Simultaneous Update"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Update both ",(0,a.kt)("inlineCode",{parentName:"li"},"w")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"b")," simultaneously"),(0,a.kt)("li",{parentName:"ul"},"Compute both update terms and store in temporary variables"),(0,a.kt)("li",{parentName:"ul"},"Copy the values of temporary variables to ",(0,a.kt)("inlineCode",{parentName:"li"},"w")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"b"))),(0,a.kt)("h3",{id:"incorrect-implementation"},"Incorrect Implementation"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Non-simultaneous update will probably work but not correct"),(0,a.kt)("li",{parentName:"ul"},"The updated ",(0,a.kt)("inlineCode",{parentName:"li"},"w")," and ",(0,a.kt)("inlineCode",{parentName:"li"},"b")," values differ from the correct simultaneous update")),(0,a.kt)("h3",{id:"conclusion-1"},"Conclusion"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Gradient descent is a powerful algorithm for optimizing models"),(0,a.kt)("li",{parentName:"ul"},"Derivatives come from calculus, but not necessary to know calculus to use gradient descent")),(0,a.kt)("h2",{id:"gradient-descent-intuition-and-learning-rate"},"Gradient Descent Intuition and Learning Rate"),(0,a.kt)("h3",{id:"introduction-2"},"Introduction"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Gradient descent algorithm updates model parameters w and b"),(0,a.kt)("li",{parentName:"ul"},"Learning rate alpha controls the step size in updating w and b"),(0,a.kt)("li",{parentName:"ul"},"Derivative term dJ/dw describes the slope of the cost function J at a given point"),(0,a.kt)("li",{parentName:"ul"},"Positive derivative means move to the left on the graph and decrease w"),(0,a.kt)("li",{parentName:"ul"},"Negative derivative means move to the right on the graph and increase w"),(0,a.kt)("li",{parentName:"ul"},"The goal is to reach the minimum of the cost function J")),(0,a.kt)("h3",{id:"gradient-descent-on-one-parameter"},"Gradient Descent on One Parameter"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Consider a cost function J of just one parameter w"),(0,a.kt)("li",{parentName:"ul"},"Plot the cost as a function of w"),(0,a.kt)("li",{parentName:"ul"},"Gradient descent updates w to w - alpha ","*"," dJ/dw"),(0,a.kt)("li",{parentName:"ul"},"Positive derivative means decrease w, move to the left on the graph"),(0,a.kt)("li",{parentName:"ul"},"Negative derivative means increase w, move to the right on the graph"),(0,a.kt)("li",{parentName:"ul"},"Goal is to decrease the cost J and reach the minimum")),(0,a.kt)("h3",{id:"choosing-the-learning-rate-alpha"},"Choosing the Learning Rate Alpha"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Alpha controls the step size in updating the parameter w"),(0,a.kt)("li",{parentName:"ul"},"Alpha too small means slow convergence to the minimum"),(0,a.kt)("li",{parentName:"ul"},"Alpha too largecan lead to overshooting the minimum and never converging"),(0,a.kt)("li",{parentName:"ul"},"It's important to choose an appropriate learning rate for effective gradient descent"),(0,a.kt)("li",{parentName:"ul"},"A good starting point for alpha is 0.01 and can be adjusted based on the specific problem")),(0,a.kt)("h3",{id:"visualizing-learning-rate"},"Visualizing Learning Rate"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"If the learning rate is too small, the algorithm takes many small steps to reach the minimum."),(0,a.kt)("li",{parentName:"ul"},"If the learning rate is too large, the algorithm takes large steps and may overshoot the minimum or oscillate around it."),(0,a.kt)("li",{parentName:"ul"},"It's ideal to have a learning rate that allows the algorithm to converge efficiently without overshooting.")),(0,a.kt)("h3",{id:"learning-rate-tuning"},"Learning Rate Tuning"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"If the learning rate is too small, the algorithm may take a long time to converge."),(0,a.kt)("li",{parentName:"ul"},"If the learning rate is too large, the algorithm may fail to converge or oscillate around the minimum."),(0,a.kt)("li",{parentName:"ul"},"You can try different learning rates and observe the behavior of the algorithm."),(0,a.kt)("li",{parentName:"ul"},"If the algorithm is not converging, try reducing the learning rate."),(0,a.kt)("li",{parentName:"ul"},"If the algorithm is converging slowly, try increasing the learning rate."),(0,a.kt)("li",{parentName:"ul"},"The learning rate is a hyperparameter that needs to be tuned for each specific problem.")),(0,a.kt)("h3",{id:"conclusion-2"},"Conclusion"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Gradient descent updates the model parameters based on the learning rate and the derivative of the cost function."),(0,a.kt)("li",{parentName:"ul"},"The learning rate controls the step size in updating the parameters."),(0,a.kt)("li",{parentName:"ul"},"Choosing an appropriate learning rate is crucial for efficient convergence of the algorithm."),(0,a.kt)("li",{parentName:"ul"},"A learning rate that is too small can result in slow convergence, while a learning rate that is too large can lead to overshooting the minimum or oscillations."),(0,a.kt)("li",{parentName:"ul"},"Tuning the learning rate is important to find the right balance for effective gradient descent.")))}u.isMDXComponent=!0}}]);