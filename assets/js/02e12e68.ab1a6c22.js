"use strict";(self.webpackChunkmyblog=self.webpackChunkmyblog||[]).push([[6496],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>m});var i=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,i,r=function(e,t){if(null==e)return{};var n,i,r={},a=Object.keys(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(i=0;i<a.length;i++)n=a[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var u=i.createContext({}),s=function(e){var t=i.useContext(u),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},c=function(e){var t=s(e.components);return i.createElement(u.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},p=i.forwardRef((function(e,t){var n=e.components,r=e.mdxType,a=e.originalType,u=e.parentName,c=o(e,["components","mdxType","originalType","parentName"]),p=s(n),m=r,h=p["".concat(u,".").concat(m)]||p[m]||d[m]||a;return n?i.createElement(h,l(l({ref:t},c),{},{components:n})):i.createElement(h,l({ref:t},c))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var a=n.length,l=new Array(a);l[0]=p;var o={};for(var u in t)hasOwnProperty.call(t,u)&&(o[u]=t[u]);o.originalType=e,o.mdxType="string"==typeof e?e:r,l[1]=o;for(var s=2;s<a;s++)l[s]=n[s];return i.createElement.apply(null,l)}return i.createElement.apply(null,n)}p.displayName="MDXCreateElement"},8174:(e,t,n)=>{n.r(t),n.d(t,{frontMatter:()=>a,contentTitle:()=>l,metadata:()=>o,toc:()=>u,default:()=>c});var i=n(7462),r=(n(7294),n(3905));const a={},l="1 - Neural networks intuition",o={unversionedId:"Advanced Learning Algorithms/Neural networks intuition",id:"Advanced Learning Algorithms/Neural networks intuition",title:"1 - Neural networks intuition",description:"Neural Networks: Mimicking the Brain and Modern Applications",source:"@site/docs/Advanced Learning Algorithms/8-Neural networks intuition.md",sourceDirName:"Advanced Learning Algorithms",slug:"/Advanced Learning Algorithms/Neural networks intuition",permalink:"/docs/Advanced Learning Algorithms/Neural networks intuition",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Advanced Learning Algorithms/8-Neural networks intuition.md",tags:[],version:"current",sidebarPosition:8,frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"7 - The problem of overditting",permalink:"/docs/Supervised Machine Learning/The problem of overditting"},next:{title:"2 - Neural network layer",permalink:"/docs/Advanced Learning Algorithms/Neural network layer"}},u=[{value:"Neural Networks: Mimicking the Brain and Modern Applications",id:"neural-networks-mimicking-the-brain-and-modern-applications",children:[{value:"Introduction",id:"introduction",children:[],level:3},{value:"Impact of Neural Networks",id:"impact-of-neural-networks",children:[],level:3},{value:"Understanding the Brain",id:"understanding-the-brain",children:[],level:3},{value:"Artificial Neural Networks",id:"artificial-neural-networks",children:[],level:3},{value:"Biological Neurons vs. Artificial Neurons",id:"biological-neurons-vs-artificial-neurons",children:[],level:3},{value:"Shifting Focus: Engineering Principles",id:"shifting-focus-engineering-principles",children:[],level:3},{value:"Data and Performance",id:"data-and-performance",children:[],level:3},{value:"Conclusion",id:"conclusion",children:[],level:3}],level:2},{value:"Neural Networks",id:"neural-networks",children:[{value:"Overview",id:"overview",children:[],level:3},{value:"Single Neuron",id:"single-neuron",children:[],level:3},{value:"Neural Network Architecture",id:"neural-network-architecture",children:[],level:3},{value:"Forward Propagation",id:"forward-propagation",children:[],level:3},{value:"Key Advantages",id:"key-advantages",children:[],level:3},{value:"Architectural Choices",id:"architectural-choices",children:[],level:3}],level:2},{value:"Neural Networks for Computer Vision",id:"neural-networks-for-computer-vision",children:[{value:"Introduction",id:"introduction-1",children:[],level:3},{value:"Feature Vector",id:"feature-vector",children:[],level:3},{value:"Neural Network Architecture",id:"neural-network-architecture-1",children:[],level:3},{value:"Visualization of Hidden Layers",id:"visualization-of-hidden-layers",children:[],level:3},{value:"Neural Network Learning",id:"neural-network-learning",children:[],level:3},{value:"Window Size in Neuron Visualizations",id:"window-size-in-neuron-visualizations",children:[],level:3},{value:"Adaptability to Different Tasks",id:"adaptability-to-different-tasks",children:[],level:3},{value:"Conclusion",id:"conclusion-1",children:[],level:3}],level:2}],s={toc:u};function c(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,i.Z)({},s,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"1---neural-networks-intuition"},"1 - Neural networks intuition"),(0,r.kt)("h2",{id:"neural-networks-mimicking-the-brain-and-modern-applications"},"Neural Networks: Mimicking the Brain and Modern Applications"),(0,r.kt)("h3",{id:"introduction"},"Introduction"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neural networks were originally inspired by the desire to mimic the human brain's learning and thinking processes."),(0,r.kt)("li",{parentName:"ul"},"While today's neural networks differ significantly from the brain, some biological motivations still influence their design."),(0,r.kt)("li",{parentName:"ul"},"Neural networks had a rollercoaster journey, gaining popularity in the 1950s, falling out of favor, and resurging in the 1980s and early 1990s."),(0,r.kt)("li",{parentName:"ul"},"The late 1990s saw a decline in interest, but from 2005, neural networks experienced a resurgence, especially with the advent of deep learning.")),(0,r.kt)("h3",{id:"impact-of-neural-networks"},"Impact of Neural Networks"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neural networks have revolutionized various application areas, starting with improved speech recognition and then making inroads into computer vision, natural language processing, and more."),(0,r.kt)("li",{parentName:"ul"},"They are now widely used in diverse fields such as climate change, medical imaging, online advertising, and product recommendations.")),(0,r.kt)("h3",{id:"understanding-the-brain"},"Understanding the Brain"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"The human brain exhibits a higher level of intelligence compared to current neural networks."),(0,r.kt)("li",{parentName:"ul"},"Neurons in the brain communicate through electrical impulses and form connections with other neurons."),(0,r.kt)("li",{parentName:"ul"},"A simplified diagram of a biological neuron shows inputs received through dendrites and outputs transmitted via the axon.")),(0,r.kt)("h3",{id:"artificial-neural-networks"},"Artificial Neural Networks"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Artificial neural networks use a simplified mathematical model of biological neurons."),(0,r.kt)("li",{parentName:"ul"},"Each artificial neuron takes inputs, performs computations, and produces an output."),(0,r.kt)("li",{parentName:"ul"},"When building neural networks, multiple neurons are simulated simultaneously to enhance computational power.")),(0,r.kt)("h3",{id:"biological-neurons-vs-artificial-neurons"},"Biological Neurons vs. Artificial Neurons"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Although there is an analogy between biological and artificial neurons, our understanding of the brain remains limited."),(0,r.kt)("li",{parentName:"ul"},"Attempting to blindly mimic the brain's complexity may not lead to building true intelligence."),(0,r.kt)("li",{parentName:"ul"},"However, even with simplified neuron models, we can develop powerful deep learning algorithms.")),(0,r.kt)("h3",{id:"shifting-focus-engineering-principles"},"Shifting Focus: Engineering Principles"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Researchers in deep learning have shifted away from relying heavily on biological motivation."),(0,r.kt)("li",{parentName:"ul"},"Instead, they leverage engineering principles to create more effective algorithms.")),(0,r.kt)("h3",{id:"data-and-performance"},"Data and Performance"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neural networks' recent success can be attributed to the availability of large amounts of data."),(0,r.kt)("li",{parentName:"ul"},"With traditional machine learning algorithms, performance reached a limit despite increasing data."),(0,r.kt)("li",{parentName:"ul"},"Neural networks, on the other hand, demonstrated the ability to improve performance as more data was provided."),(0,r.kt)("li",{parentName:"ul"},"Training larger neural networks with more artificial neurons allowed for further performance gains, especially with big data applications."),(0,r.kt)("li",{parentName:"ul"},"The rise of faster computer processors, including GPUs, contributed significantly to the advancement of deep learning.")),(0,r.kt)("h3",{id:"conclusion"},"Conclusion"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neural networks, originally inspired by the brain, have transformed various application areas."),(0,r.kt)("li",{parentName:"ul"},"While they differ from biological neurons, they provide powerful tools for solving complex problems."),(0,r.kt)("li",{parentName:"ul"},"The recent success of neural networks is due to the availability of large datasets and the ability of deep learning algorithms to exploit them effectively."),(0,r.kt)("li",{parentName:"ul"},"Understanding the brain remains a fascinating area of research, but current progress in deep learning is driven by engineering principles.")),(0,r.kt)("h2",{id:"neural-networks"},"Neural Networks"),(0,r.kt)("h3",{id:"overview"},"Overview"),(0,r.kt)("p",null,'Neural networks are powerful machine learning models inspired by biological neural networks. They consist of layers of interconnected "neurons" that transmit "activations" to each other.'),(0,r.kt)("h3",{id:"single-neuron"},"Single Neuron"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"A single neuron is like a tiny computer that inputs numbers, performs a calculation, and outputs numbers"),(0,r.kt)("li",{parentName:"ul"},"It can be thought of as logistic regression"),(0,r.kt)("li",{parentName:"ul"},'The output is called the "activation"'),(0,r.kt)("li",{parentName:"ul"},"A single neuron is a vastly simplified model of a biological neuron")),(0,r.kt)("h3",{id:"neural-network-architecture"},"Neural Network Architecture"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neurons are grouped into layers"),(0,r.kt)("li",{parentName:"ul"},"Layers:",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},"Input layer - inputs to the network"),(0,r.kt)("li",{parentName:"ul"},"Hidden layers - intermediate computations"),(0,r.kt)("li",{parentName:"ul"},"Output layer - final outputs"))),(0,r.kt)("li",{parentName:"ul"},"Each neuron in a layer is connected to every neuron in the next layer"),(0,r.kt)("li",{parentName:"ul"},"Data flows through the network in one direction from input to output")),(0,r.kt)("h3",{id:"forward-propagation"},"Forward Propagation"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Input features form a vector $\\mathbf{x}$"),(0,r.kt)("li",{parentName:"ul"},"Each hidden layer computes an activation vector $\\mathbf{a}$"),(0,r.kt)("li",{parentName:"ul"},"The activation vector is fed as input to the next layer"),(0,r.kt)("li",{parentName:"ul"},"The final layer outputs the prediction $\\hat{y}$")),(0,r.kt)("h3",{id:"key-advantages"},"Key Advantages"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Learns its own features rather than requiring manual engineering"),(0,r.kt)("li",{parentName:"ul"},"Very powerful modeling capabilities for many problems")),(0,r.kt)("h3",{id:"architectural-choices"},"Architectural Choices"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Number of hidden layers"),(0,r.kt)("li",{parentName:"ul"},"Number of neurons per hidden layer"),(0,r.kt)("li",{parentName:"ul"},"Affects model performance")),(0,r.kt)("h2",{id:"neural-networks-for-computer-vision"},"Neural Networks for Computer Vision"),(0,r.kt)("h3",{id:"introduction-1"},"Introduction"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neural networks can be applied to computer vision applications"),(0,r.kt)("li",{parentName:"ul"},"Example: Face recognition"),(0,r.kt)("li",{parentName:"ul"},"Input: Picture represented as a 1000x1000 matrix of pixel intensity values")),(0,r.kt)("h3",{id:"feature-vector"},"Feature Vector"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Image pixels can be unrolled into a vector of 1 million pixel intensity values"),(0,r.kt)("li",{parentName:"ul"},"Neural network takes this feature vector as input")),(0,r.kt)("h3",{id:"neural-network-architecture-1"},"Neural Network Architecture"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Input image X is fed into the first hidden layer"),(0,r.kt)("li",{parentName:"ul"},"Each hidden layer extracts specific features"),(0,r.kt)("li",{parentName:"ul"},"Output of each layer is fed to the next layer"),(0,r.kt)("li",{parentName:"ul"},"Final output layer estimates the probability of a person's identity")),(0,r.kt)("h3",{id:"visualization-of-hidden-layers"},"Visualization of Hidden Layers"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Trained neural networks reveal interesting features learned by hidden layers"),(0,r.kt)("li",{parentName:"ul"},"First hidden layer: Neurons detect short lines and edges"),(0,r.kt)("li",{parentName:"ul"},"Next hidden layers: Neurons detect parts of faces (eyes, nose, ears)"),(0,r.kt)("li",{parentName:"ul"},"Subsequent layers aggregate face parts to detect larger face shapes"),(0,r.kt)("li",{parentName:"ul"},"Rich set of features helps determine the identity of the person")),(0,r.kt)("h3",{id:"neural-network-learning"},"Neural Network Learning"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neural networks learn feature detectors at different hidden layers automatically"),(0,r.kt)("li",{parentName:"ul"},"No explicit instruction given to the network about what to look for"),(0,r.kt)("li",{parentName:"ul"},"Features are learned through training on data")),(0,r.kt)("h3",{id:"window-size-in-neuron-visualizations"},"Window Size in Neuron Visualizations"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neurons in different hidden layers look at different-sized regions in the image"),(0,r.kt)("li",{parentName:"ul"},"First hidden layer: Smaller windows for edge detection"),(0,r.kt)("li",{parentName:"ul"},"Second hidden layer: Bigger windows for detecting parts"),(0,r.kt)("li",{parentName:"ul"},"Third hidden layer: Even bigger windows for detecting complete shapes")),(0,r.kt)("h3",{id:"adaptability-to-different-tasks"},"Adaptability to Different Tasks"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neural networks can be trained on different datasets for different tasks"),(0,r.kt)("li",{parentName:"ul"},"Example: Training on car images results in the detection of car-related features"),(0,r.kt)("li",{parentName:"ul"},"Network automatically learns to detect features relevant to the given task")),(0,r.kt)("h3",{id:"conclusion-1"},"Conclusion"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Neural networks are powerful tools for computer vision applications")))}c.isMDXComponent=!0}}]);